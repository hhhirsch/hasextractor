# extract_population_split.py (V14 – FINAL, KOMPATIBEL)
#
# Verbesserungen:
# - Erweiterte SHORT_POP_KEEP für Meta-Aussagen (SMOFKABIVEN, VABYSMO)
# - Neuer Fallback: fallback_population_from_summary() für L'essentiel (GIVLAARI)
# - Verbesserte Priorisierungs-Logik für Kandidaten
# - Konsistente MIN_POP_CHARS = 40
# - Subpopulation-Längen-Validierung
# - FIXES: Regex-Stop-Markers, alte CLI-Signatur, keine Duplikate

import sys
import csv
import re
import logging
from pathlib import Path
from typing import Dict, Tuple

from shared_utils import (
    load_patterns,
    normalize_text,
    read_pdf_text,
    split_by_headings_v3,
    find_section_with_rule,
    fallback_extract,
    iter_pdfs,
    make_doc_id,
    first_match_rule,
    start_signal,
    progress_bar,
    end_signal,
)

# Logging einrichten
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

PATTERN_VERSION = "hybrid_v2.1"
MIN_POP_CHARS = 40  # Konsistent auf 40 gesetzt
MIN_SUBPOP_CHARS = 20
MAX_SUBPOP_LENGTH = 800

# In extract_population_split.py

# STAGE 1: Negative Patterns (rausfiltern VOR Extraktion!)
POPULATION_BLACKLIST_PATTERNS = [
    r"^Demande\s+de\s+donn[ée]es",
    r"^La\s+Commission\s+souhaite",
    r"^\d+\s+CONCLUSIONS?\s+DE\s+LA\s+COMMISSION",
    r"^[ÉE]VALUER\s+LES\s+TECHNOLOGIES",
    r"^Recommandations?\s+de\s+la\s+Commission",
    r"^de\s+la\s+d[ée]monstration.*dans\s+la\s+population",  # SMR-Text
]

def is_blacklisted_population(text: str) -> bool:
    """Prüfe ob Text aus falscher Section stammt"""
    head = text.strip()[:200].lower()
    for pat in POPULATION_BLACKLIST_PATTERNS:
        if re.search(pat, head, re.I):
            return True
    return False

# STAGE 2: Längen-Filter
def validate_population_length(text: str) -> Tuple[str, str]:
    """Validiere und kürze Population"""
    if len(text) < 40:
        return "", "too_short"
    
    # Blacklist-Check
    if is_blacklisted_population(text):
        return "", "blacklisted_section"
    
    # Zu lang (>4000)? → Kürze hart an nächster Section
    if len(text) > 4000:
        # Schneide an nächstem nummerierten Abschnitt
        next_section = re.search(r"\n\s*\d+\.?\s+[A-Z][A-Z\s]+", text[500:])
        if next_section:
            text = text[:500 + next_section.start()]
        else:
            # Fallback: erste 2000 Zeichen an Satzende
            text = text[:2000]
            last_period = text.rfind('.')
            if last_period > 1000:
                text = text[:last_period + 1]
        
        return text.strip(), "trimmed_long"
    
    return text.strip(), "ok"

# Erweiterte Keep-Patterns für kurze aber wichtige Population-Aussagen
SHORT_POP_KEEP = [
    r"population cible ne peut pas être estimée",
    r"population cible de cette sp[ée]cialit[ée]\s+ne peut\s+[êe]tre\s+estim[ée]e?",
    r"population cible\s+prévalente",
    r"population[s]?\s+cible[s]?\s+d[ée]j[àa]\s+estim[ée]e?s?",
    r"n['']est pas de nature [àa] modifier les populations cibles",
    r"population[s]?\s+cible[s]?\s+telle[s]?\s+que\s+d[ée]finie[s]?",
]

# Patterns für L'essentiel / Summary-Box
ESS_SUMMARY_PATTERNS = [
    r"avis favorable au remboursement[^.]*patients[^.]*\.",
    r"avis favorable[^.]*chez les patients[^.]*\.",
    r"avis\s+favorable[^.]{10,300}patients[^.]{10,300}\.",
]

# Subpopulation Stop-Marker (als Regex)
SUBPOP_STOP_MARKERS = [
    r"(?i)\bcomparateurs?\b",
    r"(?i)\bsynthèse\b",
    r"(?i)\bconclusion\b",
    r"(?i)\bservice médical rendu\b",
    r"(?i)\bSMR\b",
]


def _safe_section_and_rule(result) -> Tuple[str, str]:
    """Normalisiert die Rückgabe von find_section_with_rule."""
    if result is None:
        return "", ""
    if isinstance(result, tuple) and len(result) == 2:
        sec, rule_id = result
        return sec or "", rule_id or ""
    if isinstance(result, str):
        return result, ""
    return str(result), ""


def is_short_but_valid_population(text: str) -> bool:
    """Prüft ob ein kurzer Text trotzdem als gültige Population zählt."""
    if not text or len(text) < 20:
        return False
    
    text_lower = text.lower()
    for pat in SHORT_POP_KEEP:
        if re.search(pat, text_lower, flags=re.I):
            return True
    
    return False


def trim_population_block(text: str) -> str:
    """Entfernt Epidemiologie-Sections und kürzt den Population-Block sinnvoll."""
    if not text:
        return ""
    
    # Entferne Epidemiologie-Sections
    epidemio_patterns = [
        r"(?i)^\s*(?:\d+\.?\d*\s+)?[ÉE]PID[ÉE]MIOLOGIE\b.*?(?=\n\n|\Z)",
        r"(?i)\b[ÉE]PID[ÉE]MIOLOGIE\b[^\n]{0,100}\n.*?(?=\n\n|\Z)",
    ]
    
    for pat in epidemio_patterns:
        text = re.sub(pat, "", text, flags=re.DOTALL | re.MULTILINE)
    
    # Whitespace normalisieren
    text = re.sub(r'\n{3,}', '\n\n', text)
    
    return text.strip()


def fallback_population_from_indication(ind_text: str) -> str:
    """Fallback: Extrahiert Population-Infos aus Indication."""
    if not ind_text or len(ind_text) < 50:
        return ""
    
    patterns = [
        r"chez les (?:adultes|patients|enfants)[^.]{10,200}\.",
        r"(?:adultes?|patients?|enfants?)[^.]{10,150}âgés? de[^.]{10,100}\.",
        r"patients?[^.]{10,150}atteints? de[^.]{10,150}\.",
    ]
    
    for pat in patterns:
        m = re.search(pat, ind_text, flags=re.I)
        if m:
            return m.group(0).strip()
    
    return ""


def fallback_population_from_summary(full_text: str) -> str:
    """
    Sucht in 'L'essentiel' / 'Synthèse de l'avis' nach einem
    Satz mit 'patients ...' als Population-Ersatz.
    """
    if not full_text:
        return ""
    
    t = " ".join(full_text.split())
    low = t.lower()
    
    # FIX: Duplikate entfernt
    window = ""
    for anchor in ["l'essentiel", "synthèse de l'avis"]:
        idx = low.find(anchor)
        if idx != -1:
            window = t[idx : idx + 800]
            break
    
    if not window:
        window = t
    
    # Satz mit 'avis favorable ... patients ...'
    for pat in ESS_SUMMARY_PATTERNS:
        m = re.search(pat, window, flags=re.I)
        if m:
            result = m.group(0).strip()
            if len(result) >= MIN_POP_CHARS:
                return result
    
    # Generischer Satz: 'chez les patients ...'
    m = re.search(r"chez les patients[^.]{10,300}\.", window, flags=re.I)
    if m:
        result = m.group(0).strip()
        if len(result) >= MIN_POP_CHARS:
            return result
    
    return ""


def infer_sub_from_population(pop_text: str) -> str:
    """Heuristik: Versucht Subpopulation aus Population zu extrahieren."""
    if not pop_text or len(pop_text) < MIN_SUBPOP_CHARS:
        return ""
    
    sub_markers = [
        r"sous[-\s]?population[s]?",
        r"sous[-\s]?groupe[s]?",
        r"analyses?\s+en\s+sous[-\s]?groupe",
        r"population[s]?\s+sp[ée]cifique[s]?",
        r"patients?\s+en\s+[ée]chec",
        r"formes?\s+s[ée]v[èe]res?",
    ]
    
    for marker in sub_markers:
        if re.search(marker, pop_text, flags=re.I):
            match = re.search(marker, pop_text, flags=re.I)
            if match:
                start = max(0, match.start() - 100)
                end = min(len(pop_text), match.end() + 200)
                snippet = pop_text[start:end].strip()
                
                if len(snippet) >= MIN_SUBPOP_CHARS:
                    return snippet
    
    return ""


def validate_and_trim_subpopulation(sub: str, pop: str) -> str:
    """
    Validiert und trimmt Subpopulation-Text.
    
    FIX: Stop-Marker jetzt mit Regex statt .find()
    """
    if not sub:
        return ""
    
    # 1) Stoppe an falschen Sections (FIX: mit Regex)
    for marker in SUBPOP_STOP_MARKERS:
        m = re.search(marker, sub, flags=re.I)
        if m and m.start() > 20:  # Nicht wenn Marker ganz am Anfang
            sub = sub[:m.start()].strip()
            break
    
    # 2) Längen-Limit
    max_len = min(MAX_SUBPOP_LENGTH, int(len(pop) * 1.5)) if pop else MAX_SUBPOP_LENGTH
    
    if len(sub) > max_len:
        logger.debug(f"Subpopulation too long ({len(sub)}), trimming to {max_len}")
        sub = sub[:max_len].strip()
        last_period = sub.rfind('.')
        if last_period > max_len * 0.6:
            sub = sub[:last_period + 1]
    
    # 3) Validierung: Verwerfe wenn offensichtlich falsch
    if len(sub) > len(pop) * 2.0:
        logger.warning(f"Subpopulation suspiciously long ({len(sub)} vs {len(pop)}), discarding")
        return ""
    
    # 4) Prüfe auf falsche Section-Marker im Text
    for marker in SUBPOP_STOP_MARKERS:
        if re.search(marker, sub, flags=re.I):
            logger.warning(f"Subpopulation contains stop marker, discarding")
            return ""
    
    return sub


def select_best_population_candidate(candidates: list) -> Tuple[str, str]:
    """Wählt den besten Population-Kandidaten aus mehreren Optionen."""
    if not candidates:
        return "", ""
    
    # Filter: mindestens MIN_POP_CHARS oder valid short text
    valid = []
    for text, length, source, rule in candidates:
        if length >= MIN_POP_CHARS or is_short_but_valid_population(text):
            valid.append((text, length, source, rule))
    
    if not valid:
        return "", ""
    
    # Sortiere: Summary > Section > Indication, dann nach Länge
    def sort_key(item):
        text, length, source, rule = item
        priority = {'summary': 3, 'section': 2, 'indication': 1}.get(source, 0)
        return (-priority, -length)
    
    valid.sort(key=sort_key)
    
    best_text, best_len, best_source, best_rule = valid[0]
    logger.debug(f"Selected population from {best_source} (length={best_len})")
    
    return best_text, best_rule

def clean_population_block_v2(text: str) -> Tuple[str, str]:
    """Trennt klinische Population von Epidemiologie"""
    if not text:
        return "", ""
    
    sentences = re.split(r'(?<=[.!?])\s+', text)
    epidemio_markers = [
        r"(?i)^Selon\s+(?:l['']Agence|les\s+données)",
        r"(?i)^La\s+pr[ée]valence",
        r"(?i)\best\s+estim[ée]e?\s+[àa].*\d+",
    ]
    
    clean_sentences = []
    for sent in sentences:
        if any(re.search(pat, sent) for pat in epidemio_markers):
            break
        if re.search(r"(?i)\b(?:patients?|adultes?|enfants?|atteints?)\b", sent):
            clean_sentences.append(sent)
    
    return ' '.join(clean_sentences).strip(), ""

def looks_numeric_only(text: str) -> bool:
    """Prüft ob nur Zahlen, keine klinische Definition"""
    if not text or len(text) < 20:
        return True
    if len(re.findall(r'\d+', text)) > 3 and len(text) < 200:
        return True
    if not re.search(r"(?i)\b(?:patients?|atteints?|adultes?)\b", text):
        return True
    return False

def extract_one(pdf: Path, cfg_path: Path, ind_map: Dict[str, str]) -> Tuple[str, str, str, str]:
    cfg = load_patterns(cfg_path)
    options = cfg.get("options", {})
    pop_target = cfg.get("targets", {}).get("Population", {})
    pop_pats = pop_target.get("patterns", [])
    pop_min_chars = int(pop_target.get("min_chars", MIN_POP_CHARS))
    
    raw = read_pdf_text(pdf)
    text = normalize_text(raw)
    blocks = split_by_headings_v3(text, options)
    doc_id = make_doc_id(str(pdf))
    
    # 1) Standard Population-Section
    pop, pop_rule = _safe_section_and_rule(
        find_section_with_rule(blocks, pop_pats, min_chars=pop_min_chars)
    )
    
    if not pop:
        pop_fb = fallback_extract(text, pop_pats, window=1000)
        pop = pop_fb or ""
        if pop:
            pop_rule = first_match_rule(text, pop_pats) or "fallback_patterns"
    
    # ✅ FIX 1: Korrekte Einrückung!
    pop = trim_population_block(pop or "")
    if pop:
        pop, pop_status = validate_population_length(pop)
        if not pop:
            logger.debug(f"{pdf.name}: Population rejected: {pop_status}")
            pop_rule = pop_status
    
    # ✅ NEU: Regel D - Epidemiologie abtrennen
    if pop:
        pop, _ = clean_population_block_v2(pop)
    
    # ✅ NEU: Regel C - Numerik-Check + Fallback auf Indikation
    if not pop or looks_numeric_only(pop):
        ind = ind_map.get(doc_id, "")
        
        # Fallback 1: aus Indication
        fb_ind = fallback_population_from_indication(ind)
        
        # Fallback 2: aus Summary
        fb_summary = fallback_population_from_summary(text)
        
        # Wähle besten Kandidaten
        candidates = [
            (pop, len(pop or ""), 'section', pop_rule),
            (fb_summary, len(fb_summary or ""), 'summary', 'from_summary'),
            (fb_ind, len(fb_ind or ""), 'indication', 'from_indication'),
        ]
        
        pop, pop_rule = select_best_population_candidate(candidates)
    
    # 5) Subpopulation (nur wenn Population valide)
    sub = ""
    sub_rule = ""
    
    if pop and len(pop) >= MIN_POP_CHARS:
        sub = infer_sub_from_population(pop)
        if sub:
            # ✅ Duplikate-Check (ADENURIC Fix)
            if sub.strip() == pop.strip():
                logger.debug(f"{pdf.name}: Subpopulation identical to population, discarding")
                sub = ""
            else:
                sub = validate_and_trim_subpopulation(sub, pop)
                if sub:
                    sub_rule = "inferred"
    
    return pop or "", sub or "", pop_rule or "", sub_rule or ""

def main() -> None:
    # FIX: Alte CLI-Signatur wiederhergestellt
    if len(sys.argv) < 5:
        print("Usage: python extract_population_split.py <pdf_or_dir> <out_csv> <patterns_yaml> <indication_csv>")
        sys.exit(1)
    
    src = Path(sys.argv[1])
    out = Path(sys.argv[2])
    yaml_cfg = Path(sys.argv[3])
    ind_csv_path = Path(sys.argv[4])
    
    # Lade Indication-Map
    ind_map = {}
    if ind_csv_path.exists():
        with ind_csv_path.open("r", encoding="utf-8") as f:
            reader = csv.DictReader(f, delimiter=";")
            for row in reader:
                ind_map[row.get("doc_id", "")] = row.get("text", "")
        logger.info(f"Loaded {len(ind_map)} indications for fallback")
    
    pdfs = list(iter_pdfs(src))
    start_signal("extract_population_split", len(pdfs))
    
    rows = []
    
    for idx, pdf in enumerate(pdfs, start=1):
        try:
            pop_txt, sub_txt, pop_rule, sub_rule = extract_one(pdf, yaml_cfg, ind_map)
            
            doc_id = make_doc_id(str(pdf))
            
            # ALTES FORMAT: Beide in einer Zeile
            rows.append([
                str(pdf),
                doc_id,
                PATTERN_VERSION,
                pop_txt or "",
                sub_txt or "",
                pop_rule or "",
                sub_rule or "",
            ])
            
        except Exception as e:
            logger.error(f"Error processing {pdf.name}: {type(e).__name__} - {str(e)}")
            doc_id = make_doc_id(str(pdf))
            
            rows.append([
                str(pdf),
                doc_id,
                PATTERN_VERSION,
                "",
                "",
                f"__ERROR__:{type(e).__name__}",
                "",
            ])
        
        progress_bar(idx, len(pdfs), prefix="Population ")
    
    print()
    end_signal("extract_population_split")
    
    # Schreibe eine CSV im alten Format
    out.parent.mkdir(parents=True, exist_ok=True)
    with out.open("w", newline="", encoding="utf-8") as f:
        w = csv.writer(f, delimiter=";")
        w.writerow(["file", "doc_id", "pattern_version", "Population", "Subpopulation", "rule_id_population", "rule_id_subpopulation"])
        w.writerows(rows)
    
    logger.info(f"Processed {len(pdfs)} PDFs, saved to {out}")


if __name__ == "__main__":
    main()
