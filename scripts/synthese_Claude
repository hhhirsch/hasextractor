# extract_synthese.py (V14 – FINAL CORRECTED)

import sys
import csv
import re
import logging
from pathlib import Path
from typing import Tuple

from shared_utils import (
    load_patterns,
    normalize_text,
    read_pdf_text,
    split_by_headings_v3,
    find_section_with_rule,
    fallback_extract,
    iter_pdfs,
    make_doc_id,
    first_match_rule,
    start_signal,
    progress_bar,
    end_signal,
)

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

PATTERN_VERSION = "hybrid_v2.1"
MIN_SYN_CHARS = 150
MAX_SYN_LENGTH = 6000

SYN_STOP_MARKERS = [
    r"^\s*POPULATION\s+CIBLE\b",
    r"^\s*Population\s+cible\b",
    r"^\s*RECOMMANDATIONS?\b",
    r"^\s*Recommandations?\b",
    r"^\s*INFORMATIONS?\s+ADMINISTRATIVES?\b",
    r"^\s*Informations?\s+administratives?\b",
    r"^\s*ANNEXE[S]?\b",
    r"^\s*Annexe[s]?\b",
    r"^\s*RAPPEL\s+DU\s+SERVICE\s+M[ÉE]DICAL\s+RENDU\b",
]

SYN_STOP_RE = re.compile("|".join(SYN_STOP_MARKERS), re.I | re.M)


def is_pure_synthese_doc(text: str) -> bool:
    """Erkenne reine Synthèse-PDFs (KISQALI, etc.)"""
    if not text:
        return False
    
    t = " ".join(text.split())
    head = t[:600].lower()
    
    synthese_markers = [
        "synthèse de l'avis de la commission de la transparence",
        "synthese de l'avis de la commission de la transparence",
        "synthèse de l'avis",
        "synthese de l'avis",
    ]
    
    for marker in synthese_markers:
        if marker in head:
            if not re.search(r"indication(?:s)?\s+th[ée]rapeutiques?", head, re.I):
                return True
    
    return False


def trim_synthese_block(text: str, max_len: int = MAX_SYN_LENGTH) -> str:
    """Schneidet den Synthese-Block intelligent"""
    if not text:
        return ""
    
    m = SYN_STOP_RE.search(text)
    if m:
        text = text[:m.start()]
    
    t = text.strip()
    t = re.sub(r'\n{3,}', '\n\n', t)
    
    if len(t) <= max_len:
        return t
    
    shortened = t[:max_len]
    last_period = shortened.rfind(".")
    
    if last_period > max_len * 0.5:
        t = shortened[:last_period + 1]
    else:
        t = shortened.rstrip() + "..."

# In trim_synthese_block() ergänzen:
HEADER_PATTERNS = [
    r"^\d+\s+CONCLUSIONS?\s+DE\s+LA\s+COMMISSION\s*$",
    r"^CONCLUSIONS?\s+DE\s+LA\s+COMMISSION\s*$",
    r"^Avis\s+définitif\s+\d+/\d+\s*$",
    r"^Évaluation\s+Médicale.*Avis\s+\d+/\d+\s*$",
]

def trim_synthese_block(text: str, max_len: int = MAX_SYN_LENGTH) -> str:
    if not text:
        return ""
    
    # Stop-Marker wie gehabt
    m = SYN_STOP_RE.search(text)
    if m:
        text = text[:m.start()]
    
    # Header entfernen
    lines = text.split('\n')
    clean_lines = []
    for line in lines:
        # Überspringe bekannte Header/Footer
        if any(re.match(pat, line.strip(), re.I) for pat in HEADER_PATTERNS):
            continue
        clean_lines.append(line)
    
    t = '\n'.join(clean_lines).strip()
    
    return t.strip()


def _safe_section_and_rule(result) -> Tuple[str, str]:
    """Normalisiert die Rückgabe von find_section_with_rule"""
    if result is None:
        return "", ""
    if isinstance(result, tuple) and len(result) == 2:
        sec, rule_id = result
        return sec or "", rule_id or ""
    if isinstance(result, str):
        return result, ""
    return str(result), ""


def extract_one(pdf: Path, cfg_path: Path) -> Tuple[str, str]:
    """
    Extrahiert Synthese/Conclusions aus einem PDF.
    
    WICHTIG: Standard-Extraktion ZUERST, is_pure_synthese_doc nur als Fallback!
    """
    cfg = load_patterns(cfg_path)
    options = cfg.get("options", {})
    target = cfg.get("targets", {}).get("Synthese", {})
    pats = target.get("patterns", [])
    min_chars = int(target.get("min_chars", MIN_SYN_CHARS))
    
    raw = read_pdf_text(pdf)
    text = normalize_text(raw)
    
    # ===================================================================
    # STUFE 1: STANDARD-EXTRAKTION (deckt 95% der Fälle ab!)
    # ===================================================================
    blocks = split_by_headings_v3(text, options)
    
    sec, rule_id = _safe_section_and_rule(
        find_section_with_rule(blocks, pats, min_chars=min_chars)
    )
    
    # Fallback: Fließtext-Suche
    if not sec:
        sec_fb = fallback_extract(text, pats, window=2500)
        sec = sec_fb or ""
        fr = first_match_rule(text, pats)
        if fr and not rule_id:
            rule_id = fr or "fallback_patterns"
    
    cleaned = trim_synthese_block(sec or "")
    
    # Validierung: Zu kurze Schnipsel verwerfen
    if cleaned and len(cleaned) < MIN_SYN_CHARS:
        if re.search(r"CONCLUSION(S)?", cleaned, flags=re.I) and len(cleaned) >= 100:
            logger.debug(f"{pdf.name}: Short conclusion accepted ({len(cleaned)} chars)")
            return cleaned, (rule_id or "") + "|short_conclusion"
        
        logger.debug(f"{pdf.name}: Synthese too short ({len(cleaned)} chars), discarding")
        cleaned = ""
        rule_id = ""
    
    # ===================================================================
    # STUFE 2: NUR WENN STUFE 1 NICHTS FAND - Pure Synthese Doc Check
    # ===================================================================
    if not cleaned:
        if is_pure_synthese_doc(text):
            full = text.strip()
            cleaned = trim_synthese_block(full)
            
            if len(cleaned) >= 80:
                logger.debug(f"{pdf.name}: Pure synthese doc, length={len(cleaned)}")
                return cleaned, "pure_synthese_doc"
            else:
                logger.debug(f"{pdf.name}: Pure synthese doc too short ({len(cleaned)} chars)")
                return "", "pure_synthese_too_short"
    
    # ===================================================================
    # RÜCKGABE
    # ===================================================================
    if cleaned:
        logger.debug(f"{pdf.name}: Synthese via {rule_id}, length={len(cleaned)}")
    else:
        logger.debug(f"{pdf.name}: No synthese found")
        rule_id = "no_synthese_found"
    
    return cleaned or "", (rule_id or "")


def main() -> None:
    if len(sys.argv) < 4:
        print("Usage: python extract_synthese.py <pdf_or_dir> <out_csv> <patterns_yaml>")
        sys.exit(1)
    
    src = Path(sys.argv[1])
    out = Path(sys.argv[2])
    yaml_cfg = Path(sys.argv[3])
    
    pdfs = list(iter_pdfs(src))
    start_signal("extract_synthese", len(pdfs))
    
    rows = []
    for idx, pdf in enumerate(pdfs, start=1):
        try:
            txt, rule_id = extract_one(pdf, yaml_cfg)
            if txt is None:
                txt = ""
            if rule_id is None:
                rule_id = ""
            rows.append([
                str(pdf),
                "synthese",
                txt,
                make_doc_id(str(pdf)),
                PATTERN_VERSION,
                rule_id,
            ])
        except Exception as e:
            logger.error(f"Error processing {pdf.name}: {type(e).__name__} - {str(e)}")
            rows.append([
                str(pdf),
                "synthese",
                "",
                make_doc_id(str(pdf)),
                PATTERN_VERSION,
                f"__ERROR__:{type(e).__name__}",
            ])
        progress_bar(idx, len(pdfs), prefix="Synthese ")
    
    print()
    end_signal("extract_synthese")
    
    out.parent.mkdir(parents=True, exist_ok=True)
    with out.open("w", newline="", encoding="utf-8") as f:
        w = csv.writer(f, delimiter=";")
        w.writerow(["file", "field", "text", "doc_id", "pattern_version", "rule_id"])
        w.writerows(rows)
    
    logger.info(f"Processed {len(pdfs)} PDFs, saved to {out}")


if __name__ == "__main__":
    main()

