# extract_indication.py (V14 – FINAL CORRECTED)

import sys
import csv
import re
import logging
from pathlib import Path
from typing import Tuple

from shared_utils import (
    load_patterns,
    normalize_text,
    read_pdf_text,
    split_by_headings_v3,
    find_section_with_rule,
    fallback_extract,
    iter_pdfs,
    make_doc_id,
    first_match_rule,
    start_signal,
    progress_bar,
    end_signal,
)

# Logging einrichten
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

PATTERN_VERSION = "hybrid_v2.1"
MIN_INDICATION_CHARS = 80

# Stop-Marker für Indication-Section
INDICATION_STOP_MARKERS = [
    r"^\s*(?:POSOLOGIE|DOSAGE)\b",
    r"^\s*MODE\s+D['']ADMINISTRATION\b",
    r"^\s*CONTRE[-\s]?INDICATIONS?\b",
    r"^\s*MISES?\s+EN\s+GARDE\b",
    r"^\s*POPULATION\s+CIBLE\b",
    r"^\s*COMPARATEURS?\b",
    r"^\s*(?:03|3\.)\s+",
]
INDICATION_STOP_RE = re.compile("|".join(INDICATION_STOP_MARKERS), re.I | re.M)


def _safe_section_and_rule(result) -> Tuple[str, str]:
    """Normalisiert die Rückgabe von find_section_with_rule."""
    if result is None:
        return "", ""
    if isinstance(result, tuple) and len(result) == 2:
        sec, rule_id = result
        return sec or "", rule_id or ""
    if isinstance(result, str):
        return result, ""
    return str(result), ""


# Blacklist-Patterns (EINE vollständige Definition)
INDICATION_BLACKLIST_START = [
    r"^La\s+Commission\s+(?:donne|a\s+donn[ée])\s+un\s+avis\s+(?:favorable|d[ée]favorable)",
    r"^La\s+Commission\s+consid[èe]re\s+que\s+le\s+service\s+m[ée]dical\s+rendu",
    r"^Compte\s+tenu\s+de\s+l['']ensemble\s+de\s+ces\s+[ée]l[ée]ments",
    r"^Demande\s+de\s+donn[ée]es",
    r"^Recommandations?\s+(?:particuli[èe]res?|de\s+la\s+Commission)",
    r"^Service\s+M[ÉE]dical\s+Rendu\b",
    r"^Am[ée]lioration\s+du\s+Service\s+M[ée]dical\s+Rendu\b",
    r"^Liste\s+des\s+indications?\s+d[ée]j[àa]\s+[ée]valu[ée]es",
    r"^[ÉE]VALUER\s+LES\s+TECHNOLOGIES",
]

INDICATION_STOP_HEADERS = [
    r"^\s*\d{2}[\s.]*(?:CONCLUSIONS?|CONTEXTE|RAPPEL|ENVIRONNEMENT|SYNTH[ÈE]SE)\b",
    r"^\s*(?:SERVICE\s+M[ÉE]DICAL\s+RENDU|SMR)\b",
    r"^\s*(?:AM[ÉE]LIORATION\s+DU\s+SERVICE|ASMR)\b",
    r"^\s*COMPARATEURS?\s+CLINIQUEMENT\b",
    r"^\s*POPULATION\s+CIBLE\b",
    r"^\s*VALIDATION\s+DE\s+L['']INDICATION\b",
]


def is_blacklisted_indication_start(text: str) -> bool:
    """Prüfe ob Text mit verbotenen Indication-Starts beginnt"""
    head = text.strip()[:300]
    for pat in INDICATION_BLACKLIST_START:
        if re.search(pat, head, re.I | re.M):
            return True
    return False


def trim_indication_block(text: str, max_len: int = 2000) -> str:
    """Schneide Indikation intelligent ab"""
    if not text:
        return ""
    
    # 1) Blacklist-Check
    if is_blacklisted_indication_start(text):
        logger.debug("Indication rejected: blacklisted start")
        return ""
    
    # 2) "concernée(s)" am Anfang entfernen
    text = re.sub(r"^Indication\(s\)\s+concern[ée]e\(s\)\s*\n+", "", text, flags=re.I)
    
    # 3) Extrahiere Guillemets-Block (höchste Qualität)
    guillemets_match = re.search(r'«\s*(.+?)\s*»', text, re.DOTALL)
    if guillemets_match and len(guillemets_match.group(1)) >= 40:
        candidate = guillemets_match.group(1).strip()
        candidate = re.sub(r'\n+\s*\d+\s+HAS\..*$', '', candidate, flags=re.I)
        candidate = re.sub(r'\n+\s*Disponible\s+sur\s*:.*$', '', candidate, flags=re.I)
        return candidate[:max_len].strip()
    
    # 4) Stop an Evaluation-Headers
    STOP_RE = re.compile('|'.join(INDICATION_STOP_HEADERS), re.I | re.M)
    m = STOP_RE.search(text)
    if m:
        text = text[:m.start()]
    
    # 5) Fußnoten/Referenzen entfernen
    lines = text.split('\n')
    clean_lines = []
    for line in lines:
        if re.match(r'^\s*\d+\s+(?:HAS\.|http)', line, re.I):
            break
        if re.match(r'^\s*Disponible\s+sur\s*:', line, re.I):
            break
        clean_lines.append(line)
    
    t = '\n'.join(clean_lines).strip()
    t = re.sub(r'\n{3,}', '\n\n', t)
    
    # 6) Längenlimit
    if len(t) > max_len:
        last_guillemet = t[:max_len].rfind('»')
        if last_guillemet > max_len * 0.6:
            period_after = t[last_guillemet:max_len].find('.')
            if period_after != -1:
                t = t[:last_guillemet + period_after + 1]
            else:
                t = t[:last_guillemet + 1]
        else:
            shortened = t[:max_len]
            last_period = shortened.rfind('.')
            if last_period > max_len * 0.7:
                t = shortened[:last_period + 1]
            else:
                t = shortened
    
    return t.strip()


def extract_indication_by_doctype(text: str, filename: str) -> Tuple[str, str]:
    """Dokumenttyp-spezifische Indication-Extraktion"""
    fname_upper = filename.upper()
    
    # PIS_RCP: Nur Guillemets-Block akzeptieren
    if 'PIS_RCP' in fname_upper:
        guillemets = re.search(r'«\s*(.+?)\s*»', text, re.DOTALL)
        if guillemets and len(guillemets.group(1)) >= 40:
            return guillemets.group(1).strip(), "rcp_guillemets"
        return "", "rcp_no_guillemets"
    
    # PIC_EI/AP: Bevorzuge Tableau-Felder
    if any(x in fname_upper for x in ['PIC_EI', 'AP_', '_AP']):
        concernee_block = re.search(
            r'Indication\s+concern[ée]e.*?«\s*(.+?)\s*»',
            text,
            re.DOTALL | re.I
        )
        if concernee_block:
            return concernee_block.group(1).strip(), "pic_ei_tableau"
    
    # PIS_INS: Sollte nicht mit "concernée(s)" beginnen
    if 'PIS_INS' in fname_upper:
        if text.strip().startswith('concernée'):
            text = re.sub(r'^concern[ée]e\(s\)\s*\n+', '', text, flags=re.I)
    
    return text, "ok"


def fallback_indication_from_table(text: str) -> str:
    """Sucht nach Tabellenzeilen 'Indication concernée par l'évaluation'"""
    if not text:
        return ""
    
    m = re.search(
        r"Indication\s+concern[ée]e?\s+par\s+l['']évaluation\s*[:\-]\s*(.+?)(?=\n\s*\n|\n[A-Z][A-ZÉÈÎÂÔÛÄÖÜ]{3,}|$)",
        text,
        flags=re.I | re.DOTALL
    )
    
    if m:
        indication = m.group(1).strip()
        indication = re.sub(r'\s+', ' ', indication)
        return indication
    
    return ""


def fallback_indication_amm_sentence(text: str) -> str:
    """Sucht AMM-Sätze mit 'est indiqué dans/pour le traitement de'"""
    if not text:
        return ""
    
    t = " ".join(text.split())
    
    patterns = [
        r"([A-ZÉÈÎÙÂÔÄÖÜ][^.]{10,200}est\s+indiqu[ée]e?\s+(?:dans|pour)\s+le\s+traitement\s+[^.]{10,300}\.)",
        r"([A-ZÉÈÎÙÂÔÄÖÜ][^.]{10,200}sont\s+indiqu[ée]e?s?\s+(?:dans|pour)\s+le\s+traitement\s+[^.]{10,300}\.)",
    ]
    
    for pat in patterns:
        m = re.search(pat, t, flags=re.I)
        if m:
            return m.group(1).strip()
    
    return ""

def extract_one(pdf: Path, cfg: dict) -> Tuple[str, str]:
    options = cfg.get("options", {})
    target = cfg.get("targets", {}).get("Indication", {})
    pats = target.get("patterns", [])
    min_chars = int(target.get("min_chars", MIN_INDICATION_CHARS))
    
    raw = read_pdf_text(pdf)
    text = normalize_text(raw)
    blocks = split_by_headings_v3(text, options)
    
    # 1) Standard-Section-Logik
    sec, rule_id = _safe_section_and_rule(
        find_section_with_rule(blocks, pats, min_chars=min_chars)
    )
    
    if not sec:
        sec_fb = fallback_extract(text, pats, window=1500)
        sec = sec_fb or ""
        fr = first_match_rule(text, pats)
        if fr and not rule_id:
            rule_id = fr or "fallback_patterns"
    
    # 2) Trimmen und Dokumenttyp-Validierung
    cleaned = trim_indication_block(sec or "")
    
    if cleaned:
        cleaned, doctype_status = extract_indication_by_doctype(cleaned, pdf.name)
        if doctype_status != "ok":
            rule_id = (rule_id or "") + f"|{doctype_status}"
    
    # Zu kurz? → Verwerfen
    if cleaned and len(cleaned) < MIN_INDICATION_CHARS:
        cleaned = ""
        rule_id = ""
    
    # 3) Tabellen-Fallback
    if not cleaned:
        fb_tab = fallback_indication_from_table(text)
        if fb_tab and len(fb_tab) >= MIN_INDICATION_CHARS:
            logger.debug(f"{pdf.name}: Using table fallback")
            cleaned = fb_tab
            rule_id = "from_indication_table"
    
    # 4) AMM-Satz-Fallback
    if not cleaned:
        fb_amm = fallback_indication_amm_sentence(text)
        if fb_amm and len(fb_amm) >= MIN_INDICATION_CHARS:
            logger.debug(f"{pdf.name}: Using AMM sentence fallback")
            cleaned = fb_amm
            rule_id = "from_amm_sentence"
    
    # Logging
    if cleaned:
        logger.debug(f"{pdf.name}: Indication via {rule_id}, length={len(cleaned)}")
    else:
        logger.debug(f"{pdf.name}: No indication found")
    
    return cleaned or "", (rule_id or "")


def main() -> None:
    if len(sys.argv) < 4:
        print("Usage: python extract_indication.py <pdf_or_dir> <out_csv> <patterns_yaml>")
        sys.exit(1)
    
    src = Path(sys.argv[1])
    out = Path(sys.argv[2])
    yaml_cfg = Path(sys.argv[3])
    
    # YAML einmal laden
    cfg = load_patterns(yaml_cfg)
    logger.info("YAML patterns loaded once")
    
    # PDFs auflisten
    pdfs = list(iter_pdfs(src))
    start_signal("extract_indication", len(pdfs))
    
    rows = []
    
    # EINE Loop mit cfg
    for idx, pdf in enumerate(pdfs, start=1):
        try:
            txt, rule_id = extract_one(pdf, cfg)  # ← cfg, nicht yaml_cfg!
            
            if txt is None:
                txt = ""
            if rule_id is None:
                rule_id = ""
            
            rows.append([
                str(pdf),
                "indication",
                txt,
                make_doc_id(str(pdf)),
                PATTERN_VERSION,
                rule_id,
            ])
        except Exception as e:
            logger.error(f"Error processing {pdf.name}: {type(e).__name__} - {str(e)}", exc_info=True)
            rows.append([
                str(pdf),
                "indication",
                "",
                make_doc_id(str(pdf)),
                PATTERN_VERSION,
                f"__ERROR__:{type(e).__name__}",
            ])
        progress_bar(idx, len(pdfs), prefix="Indication ")
    
    print()
    end_signal("extract_indication")
    
    out.parent.mkdir(parents=True, exist_ok=True)
    with out.open("w", newline="", encoding="utf-8") as f:
        w = csv.writer(f, delimiter=";")
        w.writerow(["file", "field", "text", "doc_id", "pattern_version", "rule_id"])
        w.writerows(rows)
    
    logger.info(f"Processed {len(pdfs)} PDFs, saved to {out}")
    print()
    end_signal("extract_indication")

if __name__ == "__main__":
    main()
