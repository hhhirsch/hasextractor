# extract_comparator.py (V14 – FINAL CORRECTED)
#
# Verbesserungen gegenüber V13:
# - Logging für Debugging
# - Verbesserte Priorisierung der Heuristik
# - Generische DCI-Extraktion statt Hardcode
# - Konfigurierbare max_length aus YAML
# - NO-GO Filters für TISSEEL/LEPTOPROL/HYQVIA
# - Meta-Alternatives Handling für TARCEVA
# - CRITICAL FIXES: Apostroph-Varianten (' ' ') vollständig abgedeckt

import sys
import csv
import re
import logging
from pathlib import Path
from typing import Tuple, Any

from shared_utils import (
    load_patterns,
    normalize_text,
    read_pdf_text,
    split_by_headings_v3,
    find_section_with_rule,
    fallback_extract,
    iter_pdfs,
    make_doc_id,
    first_match_rule,
    start_signal,
    progress_bar,
    end_signal,
)

# 1) LOGGING SETUP
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# 2) KONSTANTEN
PATTERN_VERSION = "hybrid_v2.1"
MIN_COMPARATOR_CHARS = 50
MAX_COMPARATOR_LENGTH = 1000

COMPARATOR_BLACKLIST_PATTERNS = [
    r"^Demande\s+de\s+donn[ée]es",
    r"^La\s+Commission\s+souhaite",
    r"^Recommandations?\s+(?:particuli[èe]res?|de\s+la\s+Commission)",
    r"^Il\s+existe\s+des\s+alternatives?\s+th[ée]rapeutiques?",
    r"^Il\s+existe\s+des\s+alternatives?\s+m[ée]dicamenteuses?",
    r"^Compte\s+tenu",
    r"^Cette\s+sp[ée]cialit[ée]\s+est\s+un\s+g[ée]n[ée]rique\s+de\s+la\s+sp[ée]cialit[ée]\s+de\s+r[ée]f[ée]rence\.?\s*$",
]

COMPARATOR_NOGO_HEADERS = [
    r"^\s*(?:0?[4-6]|[4-6][\s.)\]]*)\s*BESOIN\s+M[ÉE]DICAL",
    r"^\s*(?:0?[5-9]|[5-9][\s.)\]]*)\s*POSOLOGIE",
    r"^\s*(?:0?[5-9]|[5-9][\s.)\]]*)\s*MODE\s+D['']ADMINISTRATION",
    r"^\s*(?:0?[89]|[89][\s.)\]]*)\s*SERVICE\s+M[ÉE]DICAL\s+RENDU",
    r"^\s*(?:0?[89]|[89][\s.)\]]*)\s*(?:SMR|ASMR)\b",
    r"^\s*(?:0?[89]|[89][\s.)\]]*)\s*AM[ÉE]LIORATION\s+DU\s+SERVICE",
]

COMPARATOR_NOGO_STARTS = [
    r"^Mode\s+d['']administration",
    r"^Pas\s+de\s+progr[èe]s\s+dans\s+la\s+prise\s+en\s+charge",
    r"^La\s+Commission\s+consid[èe]re\s+que\s+le\s+service\s+m[ée]dical",
    r"^Le\s+cancer\s+de\s+la\s+prostate",
]

COMPARATOR_VALID_SECTIONS = [
    "Comparateurs? cliniquement pertinents?",
    "Environnement th[ée]rapeutique",
    "M[ée]dicaments? de [ée]r[ée]f[ée]rence",
]

PRIORITY_RULES = ['comparateurs_section', 'no_progress_vs_ref', 'comparateurs_section_generic']

COMPARATOR_STOP_MARKERS = [
    r"^\s*(?:SERVICE\s+M[ÉE]DICAL\s+RENDU|SMR)\b",
    r"^\s*AM[ÉE]LIORATION\s+DU\s+SERVICE\s+M[ÉE]DICAL\s+RENDU\b",
    r"^\s*ASMR\b",
    r"^\s*BESOIN\s+M[ÉE]DICAL\b",
    r"^\s*ENVIRONNEMENT\s+M[ÉE]DICAL\b",
    r"^\s*POPULATION\s+CIBLE\b",
    r"^\s*SYNTH[ÈE]SE\b",
    r"^\s*RECOMMANDATIONS?\b",
]
COMPARATOR_STOP_RE = re.compile("|".join(COMPARATOR_STOP_MARKERS), re.I | re.M)

MED_REF_PATTERNS = [
    r"pas de progrès par rapport au médicament de référence\s*\((?P<ref>[^)]+)\)",
    r"pas de progrès par rapport aux princeps\s*\((?P<ref>[^)]+)\)",
    r"n['']apporte pas d['']amélioration du service médical rendu\s*\(ASMR\s*V\)\s*par rapport à\s*(?P<ref>[^.;]+)",
]

COMPARATOR_SECTION_HEADER = r"Comparateurs?\s+cliniquement\s+pertinents"
DRUG_NAME_PATTERN = r"\b([A-ZÉÈÎÙÂÔÄÖÜ][A-Z0-9\-]+)\s*\([^)]*\)"

GENERIC_SENTENCE_PATTERNS = [
    r"([^.]{0,200}g[ée]n[ée]rique[s]?\s+de\s+la\s+sp[ée]cialit[ée]\s+de\s+référence[^.]*\.)",
    r"([^.]{0,200}sp[ée]cialit[ée]\s+de\s+référence[^.]*\.)",
]


# 3) VALIDIERUNGS-FUNKTIONEN

def is_nogo_comparator(text: str) -> bool:
    """Prüfe ob Text klar KEIN Comparator ist"""
    if not text:
        return False
    
    head = text.strip()[:400]
    
    for pat in COMPARATOR_NOGO_HEADERS:
        if re.search(pat, head, re.I | re.M):
            logger.debug(f"Comparator rejected: NO-GO header matched {pat}")
            return True
    
    for pat in COMPARATOR_NOGO_STARTS:
        if re.search(pat, head, re.I | re.M):
            logger.debug(f"Comparator rejected: NO-GO start matched {pat}")
            return True
    
    if "service médical rendu" in head.lower() and "comparateur" not in head.lower():
        logger.debug("Comparator rejected: SMR without comparateur mention")
        return True
    
    return False


def is_meta_alternatives_only(text: str) -> bool:
    """Prüfe ob nur generischer Alternativ-Satz ohne Substanzen"""
    if not text or len(text) > 400:
        return False
    
    t = text.strip().lower()
    generic_only_pattern = r"^il\s+existe\s+des\s+alternatives?\s+(?:th[ée]rapeutiques?|m[ée]dicamenteuses?)[^.]*\.?\s*$"
    if re.match(generic_only_pattern, t, re.I):
        if not re.search(r'\b[A-Z][A-Z]{2,}\b', text):
            logger.debug("Comparator is meta-alternatives only")
            return True
    
    return False


def is_blacklisted_comparator(text: str) -> bool:
    """Prüfe ob Text aus falscher Section stammt"""
    head = text.strip()[:200].lower()
    for pat in COMPARATOR_BLACKLIST_PATTERNS:
        if re.search(pat, head, re.I):
            return True
    return False


def validate_comparator(text: str, section_header: str) -> Tuple[str, str]:
    """Validiere Comparator-Text"""
    if len(text) < 20:
        return "", "too_short"
    
    if is_blacklisted_comparator(text):
        return "", "blacklisted"
    
    if len(text) > 1200:
        if not any(re.search(pat, section_header, re.I) for pat in COMPARATOR_VALID_SECTIONS):
            return "", "long_wrong_section"
        text = text[:1200]
        last_period = text.rfind('.')
        if last_period > 800:
            text = text[:last_period + 1]
    
    return text.strip(), "ok"


# 4) HILFSFUNKTIONEN

def _safe_section_and_rule(result: Any) -> Tuple[str, str]:
    """Normalisiert die Rückgabe von find_section_with_rule"""
    if result is None:
        return "", ""
    if isinstance(result, tuple) and len(result) == 2:
        sec, rule_id = result
        return sec or "", rule_id or ""
    if isinstance(result, str):
        return result, ""
    return str(result), ""


def _is_numeric_heavy(line: str) -> bool:
    """Erkennt echte Tabellen-/Zahlenzeilen"""
    if not line:
        return False
    num_groups = len(re.findall(r"\b\d+(?:\.\d+)?\b", line))
    text_without_nums = re.sub(r"\d+(?:\.\d+)?", "", line).strip()
    text_length = len(text_without_nums)
    if num_groups >= 4 and text_length < 20:
        return True
    if "%" in line and num_groups >= 3 and text_length < 30:
        return True
    return False


def trim_comparator_block(text: str, max_len: int = MAX_COMPARATOR_LENGTH) -> str:
    """Schneidet den Comparator-Block intelligent"""
    if not text:
        return ""
    
    m = COMPARATOR_STOP_RE.search(text)
    if m:
        text = text[:m.start()]
    
    EVAL_CUT_PATTERNS = [
        r"\bCompte\s+tenu\b",
        r"\bDemande\s+de\s+donn[ée]es\b",
        r"\bLa\s+Commission\s+souhaite\b",
        r"\bRecommandations?\s+(?:particuli[èe]res?|de\s+la\s+Commission)\b",
    ]
    for pat in EVAL_CUT_PATTERNS:
        m = re.search(pat, text, re.I)
        if m and m.start() > 50:
            text = text[:m.start()]
            logger.debug(f"Trimmed comparator at evaluation pattern: {pat}")
            break
    
    lines = [ln for ln in text.splitlines() if ln.strip()]
    kept = [ln for ln in lines if not _is_numeric_heavy(ln)]
    t = "\n".join(kept).strip()
    t = re.sub(r'\n{3,}', '\n\n', t)
    
    if len(t) <= max_len:
        return t.strip()
    
    shortened = t[:max_len]
    last_period = shortened.rfind(".")
    if last_period > max_len * 0.5:
        t = shortened[:last_period + 1]
    else:
        t = shortened.rstrip() + "..."
    
    return t.strip()


# 5) FALLBACK-FUNKTIONEN

def fallback_no_comparator(full_text: str) -> str:
    """Spezialfall: 'il n'existe pas de comparateur'"""
    if not full_text:
        return ""
    t = " ".join(full_text.split())
    m = re.search(
        r"il n['']existe pas de comparateur cliniquement pertinent[^.]*\.",
        t,
        re.I,
    )
    if m:
        return m.group(0).strip()
    return ""


def fallback_generic_comparator(full_text: str) -> str:
    """Sucht bei Generika nach 'spécialité de référence'"""
    if not full_text:
        return ""
    t = " ".join(full_text.split())
    for pat in GENERIC_SENTENCE_PATTERNS:
        m = re.search(pat, t, re.I)
        if m:
            return m.group(1).strip()
    return ""


def fallback_alternative_treatments(full_text: str) -> str:
    """Sucht 'il existe des alternatives'"""
    if not full_text:
        return ""
    t = " ".join(full_text.split())
    m = re.search(r"il existe des alternatives?[^.]*\.", t, re.I)
    if m:
        return m.group(0).strip()
    return ""


# 6) HEURISTIK-FUNKTIONEN

def _match_first(text: str, patterns: list) -> str:
    for pat in patterns:
        m = re.search(pat, text, flags=re.IGNORECASE)
        if not m:
            continue
        ref = m.groupdict().get("ref", "").strip()
        if ref:
            return ref
    return ""


def _extract_comparator_section(text: str) -> str:
    """Sucht den 'Comparateurs cliniquement pertinents'-Block"""
    m = re.search(
        COMPARATOR_SECTION_HEADER
        + r"(.*?)(SERVICE\s+M[ÉE]DICAL\s+RENDU|ASMR|5\.[23]|POPULATION\s+CIBLE|$)",
        text,
        flags=re.IGNORECASE | re.DOTALL,
    )
    return m.group(1) if m else ""


def _extract_drug_list(block: str, exclude_prefix: str = "") -> str:
    """Extrahiert Medikamentennamen wie 'CIFLOX (ciprofloxacine)'"""
    if not block:
        return ""
    names = re.findall(DRUG_NAME_PATTERN, block)
    
    if exclude_prefix:
        cleaned = [n for n in names if not n.startswith(exclude_prefix)]
    else:
        cleaned = names
    
    if not cleaned:
        return ""
    cleaned = list(dict.fromkeys(cleaned))
    return "; ".join(cleaned)


def _extract_dci_from_product_name(product_name: str) -> str:
    """Extrahiert DCI aus Produktnamen"""
    m = re.match(r'^([a-zéèêàùâôîûäöü]+)(?:_|\s+)([A-Z]+)', product_name, re.I)
    if m:
        return m.group(1).lower()
    return ""


def _enhance_with_generic_alternatives(drugs: str, product_name: str) -> str:
    """Ergänzt 'Autres spécialités à base de X' bei Generika"""
    if not drugs:
        return drugs
    
    dci = _extract_dci_from_product_name(product_name)
    if dci:
        prefix = f"Autres spécialités à base de {dci}"
        if prefix.lower() not in drugs.lower():
            return f"{prefix}; {drugs}"
    
    return drugs


def infer_comparator(text: str, product_name: str = "") -> Tuple[str, str]:
    """Dokumentspezifische Comparator-Heuristik"""
    if not text:
        return "", ""
    
    t = " ".join(text.split())
    t_low = t.lower()
    
    if "conditions de prescription" in t_low:
        return "", "conditions_prescription_no_comp"
    
    ref = _match_first(t, MED_REF_PATTERNS)
    if ref:
        return ref, "no_progress_vs_ref"
    
    block = _extract_comparator_section(t)
    if block:
        dci = _extract_dci_from_product_name(product_name)
        exclude = dci.upper() if dci else ""
        
        drugs = _extract_drug_list(block, exclude_prefix=exclude)
        if drugs:
            drugs = _enhance_with_generic_alternatives(drugs, product_name)
            return drugs, "comparateurs_section_generic" if dci else "comparateurs_section"
    
    return "", ""


# 7) HAUPTFUNKTION

def extract_one(pdf: Path, cfg: dict) -> Tuple[str, str]:
    options = cfg.get("options", {})
    target = cfg.get("targets", {}).get("Comparateur", {})
    pats = target.get("patterns", [])
    min_chars = int(target.get("min_chars", MIN_COMPARATOR_CHARS))
    max_len = int(target.get("max_length", MAX_COMPARATOR_LENGTH))
    
    raw = read_pdf_text(pdf)
    text = normalize_text(raw)
    blocks = split_by_headings_v3(text, options)
    product_name = pdf.stem
    
    # 1) Standard-Section-Logik
    sec, rule_id = _safe_section_and_rule(
        find_section_with_rule(blocks, pats, min_chars=min_chars)
    )
    
    if not sec:
        sec_fb = fallback_extract(text, pats, window=1500)
        sec = sec_fb or ""
        fr = first_match_rule(text, pats)
        if fr and not rule_id:
            rule_id = fr or "fallback_patterns"
    
    cleaned = trim_comparator_block(sec or "", max_len=max_len)
    
    # 2) Multi-Layer Validation
    if cleaned:
        if is_nogo_comparator(cleaned):
            logger.debug(f"{pdf.name}: Comparator rejected by NO-GO filter")
            cleaned = ""
            rule_id = "nogo_comparator_rejected"
        elif is_meta_alternatives_only(cleaned):
            logger.debug(f"{pdf.name}: Comparator is meta-alternatives only")
            rule_id = (rule_id or "") + "|meta_alternatives_only"
            if len(cleaned) < 150:
                cleaned = ""
                rule_id = "meta_alternatives_discarded"
        else:
            cleaned, comp_status = validate_comparator(cleaned, rule_id or "")
            if not cleaned:
                logger.debug(f"{pdf.name}: Comparator rejected: {comp_status}")
                rule_id = comp_status
    
    if cleaned and len(cleaned) < MIN_COMPARATOR_CHARS:
        cleaned = ""
        rule_id = ""
    
    # 3) Inhaltliche Fallbacks
    if not cleaned:
        no_ccp = fallback_no_comparator(text)
        if no_ccp:
            cleaned = no_ccp
            rule_id = "no_ccp_fallback"
    
    if not cleaned:
        gen = fallback_generic_comparator(text)
        if gen:
            if "PIS_INS" in pdf.name.upper() or "PIS_RCP" in pdf.name.upper():
                cleaned = gen
                rule_id = "generic_ref|REVIEW_NEEDED"
            else:
                logger.debug(f"{pdf.name}: Generic ref too vague")
    
    if not cleaned:
        alt = fallback_alternative_treatments(text)
        if alt:
            logger.debug(f"{pdf.name}: Found generic alternatives but discarding")
            return "", "generic_alternatives_only"
    
    # 4) Spezialisierte Heuristik
    spec_comp, spec_rule = infer_comparator(text, product_name)
    
    if spec_comp:
        if not cleaned:
            cleaned = spec_comp
            rule_id = spec_rule
        elif spec_rule in PRIORITY_RULES:
            logger.debug(f"{pdf.name}: Using priority rule {spec_rule}")
            cleaned = spec_comp
            rule_id = spec_rule
        elif len(spec_comp) > len(cleaned):
            logger.debug(f"{pdf.name}: Using longer spec_comp")
            cleaned = spec_comp
            rule_id = spec_rule
    
    # 5) PIS_RI Validierung (vor finalem Return!)
    if "PIS_RI" in pdf.name.upper() and cleaned:
        drug_mentions = re.findall(r'\b[A-Z][A-Z]{2,}\b', cleaned)
        if len(drug_mentions) < 2:
            logger.debug(f"{pdf.name}: PIS_RI generic only, discarding")
            cleaned = ""
            rule_id = "pis_ri_generic_only"
    
    # 6) Bei leerem Comparator markieren
    if not cleaned:
        if not rule_id:
            rule_id = "no_comparator_found"
    
    # Logging
    if cleaned:
        logger.debug(f"{pdf.name}: Comparator via {rule_id}, length={len(cleaned)}")
    else:
        logger.debug(f"{pdf.name}: No comparator found")
    
    return cleaned or "", (rule_id or "")

def main() -> None:
    if len(sys.argv) < 4:
        print("Usage: python extract_comparator.py <pdf_or_dir> <out_csv> <patterns_yaml>")
        sys.exit(1)
    
    src = Path(sys.argv[1])
    out = Path(sys.argv[2])
    yaml_cfg = Path(sys.argv[3])
    
    # YAML einmal laden (Performance-Fix)
    cfg = load_patterns(yaml_cfg)
    logger.info("YAML patterns loaded once")
    
    # PDFs auflisten
    pdfs = list(iter_pdfs(src))
    start_signal("extract_comparator", len(pdfs))
    
    rows = []
    
    # EINE Loop mit cfg
    for idx, pdf in enumerate(pdfs, start=1):
        try:
            txt, rule_id = extract_one(pdf, cfg)  # ← cfg, nicht yaml_cfg!
            
            if txt is None:
                txt = ""
            if rule_id is None:
                rule_id = ""
            
            rows.append([
                str(pdf),
                "comparator",
                txt,
                make_doc_id(str(pdf)),
                PATTERN_VERSION,
                rule_id,
            ])
        except Exception as e:
            logger.error(f"Error processing {pdf.name}: {type(e).__name__} - {str(e)}", exc_info=True)
            rows.append([
                str(pdf),
                "comparator",
                "",
                make_doc_id(str(pdf)),
                PATTERN_VERSION,
                f"__ERROR__:{type(e).__name__}",
            ])
        progress_bar(idx, len(pdfs), prefix="Comparator ")
    
    print()
    end_signal("extract_comparator")
    
    out.parent.mkdir(parents=True, exist_ok=True)
    with out.open("w", newline="", encoding="utf-8") as f:
        w = csv.writer(f, delimiter=";")
        w.writerow(["file", "field", "text", "doc_id", "pattern_version", "rule_id"])
        w.writerows(rows)
    
    logger.info(f"Processed {len(pdfs)} PDFs, saved to {out}")

if __name__ == "__main__":
    main()
