# merge_to_excel_split.py
#
# Usage:
#   python merge_to_excel_split.py <out_dir> <population_split_csv> <out_excel>

import sys
from pathlib import Path
import os
import re

import pandas as pd


def load_csv_semicolon(path: Path) -> pd.DataFrame:
    if not path.exists():
        return pd.DataFrame()
    try:
        return pd.read_csv(path, sep=";")
    except Exception:
        return pd.read_csv(path)


def is_nonempty_series(s: pd.Series) -> pd.Series:
    return s.fillna("").astype(str).str.strip().str.len() > 0


ILLEGAL_RE = re.compile(r"[\x00-\x08\x0B\x0C\x0E-\x1F]")


def strip_illegal_excel_chars(val):
    if isinstance(val, str):
        return ILLEGAL_RE.sub("", val)
    return val


BAD_TOKENS = {
    "CT", "PIC", "PIS", "INS", "EI", "AP", "REEV", "REAP",
    "AVIS", "AVISDEF", "DEF", "MIN", "AUT", "POSTAMM", "PREAMM",
    "DECISION", "COLLEGE", "ET", "AVISCT", "AP214"
}


def guess_product_from_doc_name(path_str: str) -> str:
    """Extrahiere Produktname aus Dateiname."""
    if not path_str:
        return ""
    
    base = os.path.basename(path_str)
    stem = re.sub(r"\.(pdf|PDF)$", "", base)
    parts = stem.split("_")
    
    if len(parts) >= 3 and re.match(r"CT-\d+", parts[0], re.I) and re.match(r"CT-\d+", parts[1], re.I):
        return parts[2]
    
    if len(parts) >= 2 and re.match(r"ctap\d+", parts[0], re.I):
        for p in parts[1:]:
            token = p.strip("_-")
            if token.isupper() and len(token) >= 3 and token.upper() not in BAD_TOKENS:
                return token
    
    for p in parts:
        token = p.strip("_-")
        if token.isupper() and len(token) >= 3 and token.upper() not in BAD_TOKENS:
            return token
    
    m = re.search(r"\b([A-Z][A-Z0-9]{2,})\b", stem)
    if m:
        token = m.group(1)
        if token.upper() not in BAD_TOKENS:
            return token
    
    return ""


def flag_synthese_quality(row):
    """Markiere Synthese-QualitÃ¤t fÃ¼r Review"""
    syn = str(row.get('Synthese', '')).strip()
    
    if not syn:
        return 'empty'
    
    flags = []
    
    # Zu lang?
    if len(syn) > 4000:
        flags.append('very_long')
    
    # Zu kurz fÃ¼r echte Synthese?
    if len(syn) < 300:
        flags.append('very_short')
    
    return '|'.join(flags) if flags else 'good'


def flag_comparator_quality(row):
    """Markiere Comparator-QualitÃ¤t fÃ¼r Review"""
    comp = str(row.get('Comparator', '')).strip()
    rule_id = str(row.get('rule_id_comparator', '')).strip()
    doc_type = str(row.get('doc_name', ''))
    
    if not comp:
        return 'empty'
    
    flags = []
    
    # Generische SÃ¤tze
    generic_patterns = [
        r"Il\s+existe\s+des\s+alternatives?\s+(?:th[Ã©e]rapeutiques?|m[Ã©e]dicamenteuses?)",
        r"^Cette\s+sp[Ã©e]cialit[Ã©e]\s+est\s+un\s+g[Ã©e]n[Ã©e]rique",
    ]
    if any(re.search(pat, comp, re.I) for pat in generic_patterns):
        flags.append('generic')
    
    # Demande/Recommandations
    eval_patterns = [
        r"Demande\s+de\s+donn[Ã©e]es",
        r"La\s+Commission\s+souhaite",
        r"Recommandations?\s+(?:particuli[Ã¨e]res?|de\s+la\s+Commission)",
    ]
    if any(re.search(pat, comp, re.I) for pat in eval_patterns):
        flags.append('contains_demande')
    
    # PIS_RI speziell
    if 'PIS_RI' in doc_type.upper() and not flags:
        flags.append('pis_ri_check')
    
    # Zu kurz fÃ¼r echte Comparators?
    if len(comp) < 50 and 'no_ccp' not in rule_id:
        flags.append('very_short')
    
    return '|'.join(flags) if flags else 'good'


def clean_comparator(row):
    """Clean Comparator (nur 'good' behalten)"""
    if row.get('comparator_quality', '') == 'good':
        return row.get('Comparator', '')
    return ''


def main():
    if len(sys.argv) < 4:
        print("Usage: python merge_to_excel_split.py <out_dir> <population_split_csv> <out_excel>")
        sys.exit(1)

    out_dir = Path(sys.argv[1])
    popsplit_path = Path(sys.argv[2])
    out_xlsx = Path(sys.argv[3])

    # CSVs laden
    ind_path = out_dir / "indication.csv"
    comp_path = out_dir / "comparator.csv"
    syn_path = out_dir / "synthese.csv"

    ind = load_csv_semicolon(ind_path)
    comp = load_csv_semicolon(comp_path)
    syn = load_csv_semicolon(syn_path)
    popsplit = load_csv_semicolon(popsplit_path)

    frames = []

    # Indication
    if not ind.empty and "text" in ind.columns:
        ind_small = ind[["file", "text"]].rename(columns={"text": "Indication"})
        frames.append(ind_small)

    # Population + Subpopulation
    if not popsplit.empty:
        needed = {"file", "Population", "Subpopulation"}
        if needed.issubset(set(popsplit.columns)):
            pop_small = popsplit[["file", "Population", "Subpopulation"]]
            frames.append(pop_small)

    # Comparator MIT rule_id laden
    if not comp.empty and "text" in comp.columns:
        cols_to_load = ["file", "text"]
        if "rule_id" in comp.columns:
            cols_to_load.append("rule_id")
        comp_small = comp[cols_to_load].copy()
        comp_small.rename(columns={"text": "Comparator", "rule_id": "rule_id_comparator"}, inplace=True)
        frames.append(comp_small)

    # Synthese
    if not syn.empty and "text" in syn.columns:
        syn_small = syn[["file", "text"]].rename(columns={"text": "Synthese"})
        frames.append(syn_small)

    if not frames:
        print("Keine verwertbaren CSVs gefunden â€“ Abbruch.")
        sys.exit(0)

    from functools import reduce
    merged = reduce(lambda l, r: pd.merge(l, r, on="file", how="outer"), frames)

    # doc_name & CT-Nummer & Produktname
    merged["doc_name"] = merged["file"].astype(str).str.extract(r"([^\\/]+)$")
    merged["ct_number"] = merged["file"].astype(str).str.extract(r"(CT-\d+)", expand=False)
    merged["product_name"] = merged["file"].astype(str).apply(guess_product_from_doc_name)

    # Quality-Flags berechnen
    merged['comparator_quality'] = merged.apply(flag_comparator_quality, axis=1)
    merged['Comparator_clean'] = merged.apply(clean_comparator, axis=1)
    merged['synthese_quality'] = merged.apply(flag_synthese_quality, axis=1)

    # Spaltenreihenfolge (Fortsetzung von Zeile 243)
    cols = [
        "file", "doc_name", "ct_number", "product_name",
        "Indication", "Population", "Subpopulation",
        "Comparator", "comparator_quality", "Comparator_clean",
        "Synthese", "synthese_quality",
    ]
    other = [c for c in merged.columns if c not in cols]
    final_cols = cols + other
    merged = merged[final_cols]

    # Illegale Excel-Zeichen entfernen
    for col in merged.columns:
        if merged[col].dtype == object:
            merged[col] = merged[col].apply(strip_illegal_excel_chars)

    # Sortierung
    merged.sort_values(by=["ct_number", "product_name", "doc_name"], inplace=True, na_position='last')

    # Excel schreiben
    out_xlsx.parent.mkdir(parents=True, exist_ok=True)
    merged.to_excel(out_xlsx, index=False, engine="openpyxl")
    
    print(f"âœ… Excel erstellt: {out_xlsx}")
    print(f"   Zeilen: {len(merged)}")
    print(f"   Spalten: {len(merged.columns)}")
    
    # Quality-Statistik
    if 'comparator_quality' in merged.columns:
        comp_stats = merged['comparator_quality'].value_counts()
        print("\nðŸ“Š Comparator Quality:")
        for quality, count in comp_stats.items():
            print(f"   {quality}: {count}")
    
    if 'synthese_quality' in merged.columns:
        syn_stats = merged['synthese_quality'].value_counts()
        print("\nðŸ“Š Synthese Quality:")
        for quality, count in syn_stats.items():
            print(f"   {quality}: {count}")

if __name__ == "__main__":
    main()
